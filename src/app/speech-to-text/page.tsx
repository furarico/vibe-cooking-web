'use client';

import { useState, useRef } from 'react';

declare global {
  interface Window {
    SpeechRecognition: any;
    webkitSpeechRecognition: any;
  }
}

type RecognitionStatus = 'idle' | 'listening' | 'processing' | 'success' | 'error';

// ãƒˆãƒªã‚¬ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œçŸ¥æ©Ÿèƒ½
const detectTriggerWords = (text: string) => {
  const nextKeywords = ['æ¬¡', 'ã¤ã', 'ãƒ„ã‚®', 'æ¬¡ã®', 'ã¤ãã®', 'ãƒã‚¯ã‚¹ãƒˆ', 'next', 'é€²ã‚“ã§'];
  const prevKeywords = ['å‰', 'ã¾ãˆ', 'ãƒã‚¨', 'å‰ã®', 'ã¾ãˆã®', 'ãƒãƒƒã‚¯', 'back', 'æˆ»ã‚‹', 'ã‚‚ã©ã‚‹', 'ã‚‚ã©ã£ã¦', 'æˆ»ã£ã¦'];

  const normalizedText = text.toLowerCase();

  const hasNext = nextKeywords.some(keyword =>
    normalizedText.includes(keyword.toLowerCase())
  );

  const hasPrev = prevKeywords.some(keyword =>
    normalizedText.includes(keyword.toLowerCase())
  );

  return { hasNext, hasPrev };
};

export default function SpeechToText() {
  const [isRecording, setIsRecording] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [interimTranscript, setInterimTranscript] = useState('');
  const [isProcessing, setIsProcessing] = useState(false);
  const [status, setStatus] = useState<RecognitionStatus>('idle');
  const [statusMessage, setStatusMessage] = useState('');
  const [shouldRestart, setShouldRestart] = useState(false);
  const [isTranscriptCompleted, setIsTranscriptCompleted] = useState(false);
  const [triggerHistory, setTriggerHistory] = useState<string[]>([]);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const chunksRef = useRef<Blob[]>([]);
  const recognitionRef = useRef<any>(null);
  const restartTimeoutRef = useRef<NodeJS.Timeout | null>(null);

  const startRecording = async () => {
    try {
      // Web Speech APIã‚’ç›´æ¥ä½¿ç”¨ã™ã‚‹å ´åˆ
      if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        const recognition = new SpeechRecognition();

        recognition.lang = 'ja-JP';
        recognition.continuous = true;
        recognition.interimResults = true;
        recognition.maxAlternatives = 1;

        recognition.onstart = () => {
          setIsRecording(true);
          setStatus('listening');
          setStatusMessage('éŸ³å£°ã‚’èã„ã¦ã„ã¾ã™...');
        };

        recognition.onresult = (event: { resultIndex: any; results: string | any[]; }) => {
          let finalText = '';
          let interimText = '';

          for (let i = event.resultIndex; i < event.results.length; i++) {
            const transcriptPart = event.results[i][0].transcript;
            if (event.results[i].isFinal) {
              finalText += transcriptPart;
            } else {
              interimText += transcriptPart;
            }
          }

          // æ–°ã—ãç¢ºå®šã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚‹å ´åˆã®ã¿è¿½åŠ 
          if (finalText) {
            // ãƒˆãƒªã‚¬ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œçŸ¥
            const { hasNext, hasPrev } = detectTriggerWords(finalText);

            let triggerMessage = '';
            if (hasNext) {
              triggerMessage = 'ã€Œæ¬¡ã€ã‚’æ„ŸçŸ¥ã—ã¾ã—ãŸ';
              setTriggerHistory(prev => [...prev, `${new Date().toLocaleTimeString()}: æ¬¡ãƒˆãƒªã‚¬ãƒ¼æ¤œçŸ¥ - "${finalText}"`]);
            }
            if (hasPrev) {
              triggerMessage = 'ã€Œå‰ã€ã‚’æ„ŸçŸ¥ã—ã¾ã—ãŸ';
              setTriggerHistory(prev => [...prev, `${new Date().toLocaleTimeString()}: å‰ãƒˆãƒªã‚¬ãƒ¼æ¤œçŸ¥ - "${finalText}"`]);
            }

            // å‰å›ã®æ–‡å­—èµ·ã“ã—ãŒå®Œäº†ã—ã¦ã„ãŸå ´åˆã¯ç½®ãæ›ãˆã€ãã†ã§ãªã‘ã‚Œã°è¿½åŠ 
            if (isTranscriptCompleted) {
              setTranscript(finalText);
              setIsTranscriptCompleted(false);
            } else {
              setTranscript(prev => prev + finalText);
            }

            // ç¢ºå®šå¾Œã€çŸ­æ™‚é–“successã‚’è¡¨ç¤ºã—ã¦ã‹ã‚‰listeningã«æˆ»ã‚‹
            setStatus('success');
            setStatusMessage(triggerMessage || 'æ–‡å­—èµ·ã“ã—å®Œäº†');
            setIsTranscriptCompleted(true);

            setTimeout(() => {
              if (shouldRestart && isRecording) {
                setStatus('listening');
                setStatusMessage('éŸ³å£°ã‚’èã„ã¦ã„ã¾ã™...');
              }
            }, 500);
          }

          // ä¸­é–“çµæœã‚’æ›´æ–°
          setInterimTranscript(interimText);

          // ä¸­é–“çµæœãŒã‚ã‚‹å ´åˆã¯å‡¦ç†ä¸­çŠ¶æ…‹
          if (interimText && !finalText) {
            setStatus('processing');
            setStatusMessage('éŸ³å£°ã‚’èªè­˜ä¸­...');
          }
        };

        recognition.onerror = (event: { error: string; }) => {
          console.error('Speech recognition error:', event.error);

          // no-speechã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯è‡ªå‹•çš„ã«å†é–‹ã‚’è©¦è¡Œ
          if (event.error === 'no-speech' && shouldRestart) {
            console.log('No speech detected, will restart...');
            setStatus('listening');
            setStatusMessage('éŸ³å£°ã‚’å¾…æ©Ÿä¸­...');
            // onendã‚¤ãƒ™ãƒ³ãƒˆã§è‡ªå‹•çš„ã«å†é–‹ã•ã‚Œã‚‹
            return;
          }

          // ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯åœæ­¢
          setIsRecording(false);
          setShouldRestart(false);
          setStatus('error');
          setStatusMessage(`éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: ${event.error}`);

          // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’ã‚¯ãƒªã‚¢
          if (restartTimeoutRef.current) {
            clearTimeout(restartTimeoutRef.current);
            restartTimeoutRef.current = null;
          }
        };

        recognition.onend = () => {
          console.log('Recognition ended, shouldRestart:', shouldRestart);
          setInterimTranscript(''); // éŒ²éŸ³çµ‚äº†æ™‚ã«ä¸­é–“çµæœã‚’ã‚¯ãƒªã‚¢

          // ã‚¨ãƒ©ãƒ¼ã§ãªã„å ´åˆã€ã‹ã¤shouldRestartãŒtrueã®å ´åˆã¯è‡ªå‹•çš„ã«å†é–‹
          if (shouldRestart && status !== 'error') {
            restartTimeoutRef.current = setTimeout(() => {
              if (shouldRestart && recognitionRef.current) {
                try {
                  console.log('Restarting recognition...');
                  recognitionRef.current.start();
                } catch (error) {
                  console.error('Failed to restart recognition:', error);
                  setIsRecording(false);
                  setShouldRestart(false);
                  setStatus('error');
                  setStatusMessage('éŸ³å£°èªè­˜ã®å†é–‹ã«å¤±æ•—ã—ã¾ã—ãŸ');
                }
              }
            }, 100); // çŸ­ã„é…å»¶ã§å†é–‹
          } else {
            setIsRecording(false);
            setShouldRestart(false);
            if (status !== 'error') {
              setStatus('idle');
              setStatusMessage('');
            }
          }
        };

        recognitionRef.current = recognition;
        setShouldRestart(true); // è‡ªå‹•å†é–‹ã‚’æœ‰åŠ¹ã«ã™ã‚‹
        setIsTranscriptCompleted(false); // éŒ²éŸ³é–‹å§‹æ™‚ã«ãƒªã‚»ãƒƒãƒˆ
        recognition.start();
        return;
      }

      // Web Speech APIãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯MediaRecorderã‚’ä½¿ç”¨
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const mediaRecorder = new MediaRecorder(stream);
      mediaRecorderRef.current = mediaRecorder;
      chunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          chunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = async () => {
        const audioBlob = new Blob(chunksRef.current, { type: 'audio/wav' });
        await transcribeAudio(audioBlob);
        stream.getTracks().forEach(track => track.stop());
      };

      mediaRecorder.start();
      setIsRecording(true);
    } catch (error) {
      console.error('Error accessing microphone:', error);
      alert('ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒè¨±å¯ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚');
    }
  };

  const stopRecording = () => {
    setShouldRestart(false); // è‡ªå‹•å†é–‹ã‚’ç„¡åŠ¹ã«ã™ã‚‹

    // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’ã‚¯ãƒªã‚¢
    if (restartTimeoutRef.current) {
      clearTimeout(restartTimeoutRef.current);
      restartTimeoutRef.current = null;
    }

    // Web Speech APIã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹å ´åˆ
    if (recognitionRef.current) {
      recognitionRef.current.stop();
      setInterimTranscript('');
      return;
    }

    // MediaRecorderã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹å ´åˆ
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
      setIsProcessing(true);
    }
  };

  const transcribeAudio = async (audioBlob: Blob) => {
    try {
      // Web Speech APIã‚’ä½¿ç”¨ã—ãŸéŸ³å£°èªè­˜
      if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        const recognition = new SpeechRecognition();

        recognition.lang = 'ja-JP';
        recognition.continuous = false;
        recognition.interimResults = false;

        return new Promise((resolve, reject) => {
          recognition.onresult = (event: { results: { transcript: any; }[][]; }) => {
            const transcript = event.results[0][0].transcript;
            setTranscript(transcript);
            setIsProcessing(false);
            resolve(transcript);
          };

          recognition.onerror = (event: { error: string; }) => {
            console.error('Speech recognition error:', event.error);
            setIsProcessing(false);
            reject(new Error('éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: ' + event.error));
          };

          recognition.start();
        });
      } else {
        // Web Speech APIãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯ã‚µãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ‰APIã‚’ä½¿ç”¨
        const formData = new FormData();
        formData.append('audio', audioBlob, 'audio.wav');

        const response = await fetch('/api/speech-to-text', {
          method: 'POST',
          body: formData,
        });

        if (!response.ok) {
          throw new Error('éŸ³å£°ã®æ–‡å­—èµ·ã“ã—ã«å¤±æ•—ã—ã¾ã—ãŸ');
        }

        const data = await response.json();
        setTranscript(data.transcript);
      }
    } catch (error) {
      console.error('Error transcribing audio:', error);
      alert('éŸ³å£°ã®æ–‡å­—èµ·ã“ã—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚');
    } finally {
      setIsProcessing(false);
    }
  };

  const clearTranscript = () => {
    setTranscript('');
    setInterimTranscript('');
    setStatus('idle');
    setStatusMessage('');
    setShouldRestart(false);
    setIsTranscriptCompleted(false);

    // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’ã‚¯ãƒªã‚¢
    if (restartTimeoutRef.current) {
      clearTimeout(restartTimeoutRef.current);
      restartTimeoutRef.current = null;
    }
  };

  const getStatusColor = () => {
    switch (status) {
      case 'listening': return 'text-blue-600';
      case 'processing': return 'text-yellow-600';
      case 'success': return 'text-green-600';
      case 'error': return 'text-red-600';
      default: return 'text-gray-500';
    }
  };

  const getStatusIcon = () => {
    switch (status) {
      case 'listening': return 'ğŸ¤';
      case 'processing': return 'â³';
      case 'success': return 'âœ…';
      case 'error': return 'âŒ';
      default: return 'ğŸ’¬';
    }
  };

  return (
    <div className="min-h-screen bg-gray-50 py-8">
      <div className="max-w-2xl mx-auto px-4">
        <h1 className="text-3xl font-bold text-center mb-8 text-gray-800">
          éŸ³å£°æ–‡å­—èµ·ã“ã—
        </h1>

        <div className="bg-white rounded-lg shadow-md p-6 mb-6">
          <div className="flex flex-col items-center space-y-4">
            <div className="flex space-x-4">
              <button
                onClick={startRecording}
                disabled={isRecording || isProcessing}
                className={`px-6 py-3 rounded-lg font-medium ${
                  isRecording || isProcessing
                    ? 'bg-gray-300 cursor-not-allowed'
                    : 'bg-red-500 hover:bg-red-600 text-white'
                }`}
              >
                {isRecording ? 'éŒ²éŸ³ä¸­...' : 'éŒ²éŸ³é–‹å§‹'}
              </button>

              <button
                onClick={stopRecording}
                disabled={!isRecording || isProcessing}
                className={`px-6 py-3 rounded-lg font-medium ${
                  !isRecording || isProcessing
                    ? 'bg-gray-300 cursor-not-allowed'
                    : 'bg-blue-500 hover:bg-blue-600 text-white'
                }`}
              >
                éŒ²éŸ³åœæ­¢
              </button>
            </div>

            {status !== 'idle' && (
              <div className={`flex items-center space-x-2 font-medium ${getStatusColor()}`}>
                <span className="text-lg">{getStatusIcon()}</span>
                <span>{statusMessage}</span>
                {status === 'listening' && (
                  <div className="w-3 h-3 bg-blue-500 rounded-full animate-pulse"></div>
                )}
                {status === 'processing' && (
                  <div className="w-3 h-3 bg-yellow-500 rounded-full animate-spin border-2 border-transparent border-t-yellow-600"></div>
                )}
              </div>
            )}
          </div>
        </div>

        <div className="bg-white rounded-lg shadow-md p-6">
          <div className="flex justify-between items-center mb-4">
            <div className="flex items-center space-x-3">
              <h2 className="text-xl font-semibold text-gray-800">
                æ–‡å­—èµ·ã“ã—çµæœ
              </h2>
              {status !== 'idle' && (
                <div className={`flex items-center space-x-1 text-sm ${getStatusColor()}`}>
                  <span>{getStatusIcon()}</span>
                  <span className="font-medium">{statusMessage}</span>
                </div>
              )}
            </div>
            <button
              onClick={clearTranscript}
              className="px-4 py-2 text-sm bg-gray-500 hover:bg-gray-600 text-white rounded disabled:bg-gray-300 disabled:cursor-not-allowed"
              disabled={!transcript && !interimTranscript}
            >
              ã‚¯ãƒªã‚¢
            </button>
          </div>
          <div className={`rounded p-4 min-h-[100px] border-2 ${
            status === 'error' ? 'bg-red-50 border-red-200' :
            status === 'success' ? 'bg-green-50 border-green-200' :
            status === 'processing' ? 'bg-yellow-50 border-yellow-200' :
            status === 'listening' ? 'bg-blue-50 border-blue-200' :
            'bg-gray-50 border-gray-200'
          }`}>
            <p className="text-gray-800 leading-relaxed whitespace-pre-wrap">
              {transcript}
              {interimTranscript && (
                <span className="text-blue-600 italic bg-blue-100 px-1 rounded">
                  {interimTranscript}
                </span>
              )}
            </p>
            {!transcript && !interimTranscript && (
              <p className="text-gray-400 italic flex items-center space-x-2">
                <span>ğŸ¤</span>
                <span>éŸ³å£°èªè­˜ã‚’é–‹å§‹ã—ã¦ãã ã•ã„...</span>
              </p>
            )}
          </div>
        </div>

        {/* ãƒˆãƒªã‚¬ãƒ¼å±¥æ­´ã‚»ã‚¯ã‚·ãƒ§ãƒ³ */}
        {triggerHistory.length > 0 && (
          <div className="bg-white rounded-lg shadow-md p-6 mt-6">
            <div className="flex justify-between items-center mb-4">
              <h3 className="text-lg font-semibold text-gray-800">
                ãƒˆãƒªã‚¬ãƒ¼æ¤œçŸ¥å±¥æ­´
              </h3>
              <button
                onClick={() => setTriggerHistory([])}
                className="px-3 py-1 text-sm bg-gray-500 hover:bg-gray-600 text-white rounded"
              >
                å±¥æ­´ã‚’ã‚¯ãƒªã‚¢
              </button>
            </div>
            <div className="space-y-2 max-h-60 overflow-y-auto">
              {triggerHistory.slice(-10).reverse().map((item, index) => (
                <div
                  key={index}
                  className="p-3 bg-gray-50 rounded border-l-4 border-blue-400"
                >
                  <p className="text-sm text-gray-700 font-mono">{item}</p>
                </div>
              ))}
            </div>
          </div>
        )}
      </div>
    </div>
  );
}